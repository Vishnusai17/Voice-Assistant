# -*- coding: utf-8 -*-
"""GDG-Voice-Assistant-Gemini

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p8cDIEq5k_wONnWMdHPehnXBCKrDOWQh#scrollTo=Z1GnhtkyPQf7
"""

!pip -q install google-generativeai google-cloud-speech==2.* google-cloud-texttospeech pydub ipywidgets
from IPython.display import Audio, HTML
import os, base64, json

from google.colab import files
uploaded = files.upload()                      # pick your <project-sa>.json
sa_path = list(uploaded.keys())[0]
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = sa_path
print("Service account set at:", sa_path)

import google.generativeai as genai
GEMINI_API_KEY = input("PUT YOUR GEMINI API HERE : ").strip()
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel("gemini-1.5-flash")  # or "gemini-1.5-flash"

from google.colab import output
import base64
import subprocess

last_audio_path = None

def _save_audio(b64_str):
    """Receive audio blob from JS and save as WAV"""
    global last_audio_path
    with open("/content/input.webm", "wb") as f:
        f.write(base64.b64decode(b64_str))
    subprocess.run(
        ["ffmpeg", "-y", "-i", "/content/input.webm",
         "-ar", "16000", "-ac", "1", "-f", "wav", "/content/input.wav"],
        stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
    )
    last_audio_path = "/content/input.wav"
    print("Saved:", last_audio_path)

# ‚úÖ Correct registration
output.register_callback('py_save_audio', _save_audio)

SYSTEM_PROMPT = ("You are a concise, friendly personal voice assistant. "
                 "Keep answers short and helpful.")
def ask_gemini(user_text):
    out = model.generate_content(user_text if not SYSTEM_PROMPT else
                                 f"{SYSTEM_PROMPT}\nUser: {user_text}\nAssistant:")
    return (out.text or "").strip()

from google.cloud import texttospeech

def tts(text, voice="en-US-Neural2-C", rate=1.0):
    client = texttospeech.TextToSpeechClient()
    synthesis_input = texttospeech.SynthesisInput(text=text)
    v = texttospeech.VoiceSelectionParams(language_code="en-US", name=voice)
    cfg = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3,
                                   speaking_rate=rate)
    audio = client.synthesize_speech(input=synthesis_input, voice=v, audio_config=cfg)
    out = "/content/reply.mp3"
    with open(out,"wb") as f: f.write(audio.audio_content)
    return out

def run_once():
    if not last_audio_path:
        print("Record first, then run again.")
        return
    print("Transcribing‚Ä¶")
    user = transcribe_wav(last_audio_path)
    print("üë§", user)
    reply = ask_gemini(user)
    print("ü§ñ", reply)
    path = tts(reply)
    display(Audio(path, autoplay=True))

# Use after recording:
# run_once()

import google.generativeai as genai
genai.configure(api_key="YOUR_GEMINI_API_KEY")
test = genai.GenerativeModel("gemini-1.5-flash")
print(test.generate_content("Hello from workshop test!").text)

import google.generativeai as genai

genai.configure(api_key="YOUR_GEMINI_API_KEY")

# List all available models for your account
for m in genai.list_models():
    print(m.name)

!pip install google-cloud-speech google-cloud-texttospeech google-generativeai gradio ffmpeg-python --quiet
!pip install -U google-generativeai --quiet

import os, io, time, subprocess, gradio as gr
from google.colab import files
import google.cloud.speech as speech
import google.cloud.texttospeech as tts
import google.generativeai as genai

# ========= 1Ô∏è‚É£ Upload JSON Key ==========
if not any(f.endswith(".json") for f in os.listdir("/content")):
    print("‚ö†Ô∏è Please upload your Google Cloud JSON key file:")
    uploaded = files.upload()
key_path = [f for f in os.listdir("/content") if f.endswith(".json")][0]
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = f"/content/{key_path}"
print(f"‚úÖ Loaded credentials: {key_path}")

# ========= 2Ô∏è‚É£ Enter Gemini API Key ==========
GEMINI_KEY = input("üîë Enter your Gemini API Key: ").strip()
genai.configure(api_key=GEMINI_KEY)
model = genai.GenerativeModel("models/gemini-2.5-flash")

# ========= 3Ô∏è‚É£ Compress Audio ==========
def compress_audio(file_path):
    new_path = "/tmp/short.wav"
    subprocess.run(["ffmpeg", "-y", "-i", file_path, "-ac", "1", "-ar", "16000", new_path],
                   stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    return new_path

# ========= 4Ô∏è‚É£ Speech-to-Text ==========
def transcribe_wav(file_path):
    try:
        client = speech.SpeechClient()
        with io.open(file_path, "rb") as f:
            content = f.read()
        audio = speech.RecognitionAudio(content=content)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,
            language_code="en-US",
        )
        print("üéôÔ∏è Transcribing...")
        start = time.time()
        response = client.recognize(config=config, audio=audio)
        print(f"‚úÖ STT done in {round(time.time()-start,2)}s")
        if not response.results:
            return "No speech detected."
        return response.results[0].alternatives[0].transcript
    except Exception as e:
        return f"‚ùå STT Error: {e}"

# ========= 5Ô∏è‚É£ Gemini Reply ==========
def ask_gemini(text):
    try:
        print("ü§ñ Generating reply...")
        reply = model.generate_content(f"You are a helpful voice assistant. User said: {text}").text
        print("‚úÖ Gemini replied.")
        return reply
    except Exception as e:
        print("‚ùå Gemini Error:", e)
        return f"Error: {e}"

# ========= 6Ô∏è‚É£ Text-to-Speech ==========
def speak_text(text):
    try:
        client = tts.TextToSpeechClient()
        synthesis_input = tts.SynthesisInput(text=text)
        voice = tts.VoiceSelectionParams(language_code="en-US", name="en-US-Neural2-C")
        audio_config = tts.AudioConfig(audio_encoding=tts.AudioEncoding.MP3)
        response = client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)
        out_path = "/tmp/reply.mp3"
        with open(out_path, "wb") as out:
            out.write(response.audio_content)
        return out_path
    except Exception as e:
        print("‚ùå TTS Error:", e)
        return None

# ========= 7Ô∏è‚É£ Full Pipeline ==========
def voice_assistant(audio):
    if not audio:
        return "No audio", "Please record something", None
    path = compress_audio(audio)
    text = transcribe_wav(path)
    reply = ask_gemini(text)
    audio_out = speak_text(reply)
    return text, reply, audio_out

# ========= 8Ô∏è‚É£ Gradio UI ==========
with gr.Blocks(title="Google Cloud Voice Assistant") as demo:
    gr.Markdown("## üéôÔ∏è Speak to the AI Assistant\nPowered by Google Cloud Speech, TTS & Gemini AI")
    audio_in = gr.Audio(sources=["microphone"], type="filepath", label="üé§ Speak Now")
    with gr.Row():
        transcript = gr.Textbox(label="üß† Transcription")
        reply = gr.Textbox(label="ü§ñ Assistant Reply")
    audio_out = gr.Audio(label="üîä Voice Reply")
    gr.Markdown("‚úÖ Click Record, speak, and get Gemini‚Äôs voice reply back!")
    audio_in.change(fn=voice_assistant, inputs=audio_in, outputs=[transcript, reply, audio_out])

demo.launch(debug=True)
